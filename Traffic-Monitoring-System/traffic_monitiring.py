# -*- coding: utf-8 -*-
"""Traffic_monitiring.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PV7Fk35plPh0QUcii0yhD2QNvIdlNjEO
"""

import sys
!{sys.executable} -m pip install ultralytics

import cv2
import numpy as np
from ultralytics import YOLO

model = YOLO("yolov8n.pt")   # lightweight model

video_path = "traffics.mp4"   # change if needed
cap = cv2.VideoCapture(video_path)

if not cap.isOpened():
    print("Video not opened")
else:
    print("Video loaded")

# ---------------------------------------------------------
# Storage for previous vehicle positions (for tracking)
# Key = vehicle ID, Value = (center_x, center_y)
prev_centers = {}

# Stores how many frames a vehicle has barely moved (for stopped vehicle detection)
stop_frames = {}

# Unique ID counter for vehicles
next_id = 0

# Conversion factor (approx): pixels â†’ meters
PIXEL_TO_METER = 0.05

# Video frame rate (used for speed calculation)
FPS = 30

# Horizontal reference line (middle of frame)
count_line_y = None

# Vehicle categories
TWO_WHEELER = ["motorcycle"]
FOUR_WHEELER = ["car", "truck", "bus"]

# Thresholds for stopped vehicle detection
STOP_PIXEL_THRESHOLD = 2      # very small movement
STOP_FRAME_LIMIT = 30        # ~1 second if FPS = 30

while True:

    # ---------------------------------------------------------
    # Read next video frame
    ret, frame = cap.read()
    if not ret:
        print("End of video")
        break

    # Resize frame for faster processing
    frame = cv2.resize(frame,(640,480))
    h,w = frame.shape[:2]

    # Draw reference line only once
    if count_line_y is None:
        count_line_y = h//2

    # ---------------------------------------------------------
    # YOLO detects vehicles in the current frame
    results = model(frame, stream=True)

    # Counters
    vehicle_count = 0
    two_wheeler_count = 0
    four_wheeler_count = 0

    # Store centers detected in this frame
    current_centers = {}

    # ---------------------------------------------------------
    # Loop through YOLO detections
    for r in results:
        boxes = r.boxes

        for box in boxes:

            # Get class name (car, bike, bus, etc.)
            cls = int(box.cls[0])
            label = model.names[cls]

            # Ignore non-vehicle objects
            if label not in TWO_WHEELER + FOUR_WHEELER:
                continue

            # Bounding box coordinates
            x1,y1,x2,y2 = map(int, box.xyxy[0])

            # Center of vehicle
            cx = (x1+x2)//2
            cy = (y1+y2)//2

            # ---------------------------------------------------------
            # Count 2-wheelers and 4-wheelers
            if label in TWO_WHEELER:
                two_wheeler_count += 1
            else:
                four_wheeler_count += 1

            # ---------------------------------------------------------
            # Simple centroid-based tracking (assign same ID if close)
            assigned = False
            for vid,(px,py) in prev_centers.items():
                if abs(cx-px)+abs(cy-py) < 40:
                    current_centers[vid]=(cx,cy)
                    vehicle_id = vid
                    assigned = True
                    break

            # New vehicle if no match found
            if not assigned:
                current_centers[next_id]=(cx,cy)
                vehicle_id = next_id
                next_id += 1

            # ---------------------------------------------------------
            # Speed estimation (distance between frames)
            speed = 0
            dx = 0   # initialize dx
            dy = 0


            if vehicle_id in prev_centers:
                dx = cx - prev_centers[vehicle_id][0]
                dy = cy - prev_centers[vehicle_id][1]
                dist = np.sqrt(dx*dx + dy*dy)
                speed = int(dist * PIXEL_TO_METER * FPS)

            # ---------------------------------------------------------
            # Wrong-way detection (example: upward movement)
            wrong_way = False
            if dy < 0:
                wrong_way = True

            # ---------------------------------------------------------
            # Stopped vehicle detection
            if vehicle_id not in stop_frames:
                stop_frames[vehicle_id] = 0

            if abs(dx) < STOP_PIXEL_THRESHOLD and abs(dy) < STOP_PIXEL_THRESHOLD:
                stop_frames[vehicle_id] += 1
            else:
                stop_frames[vehicle_id] = 0

            stopped = stop_frames[vehicle_id] > STOP_FRAME_LIMIT

            # ---------------------------------------------------------
            # Box color logic
            color = (0,255,0)          # green = normal
            if wrong_way:
                color = (0,0,255)     # red = wrong way
            if stopped:
                color = (0,255,255)   # yellow = stopped vehicle

            # Draw bounding box
            cv2.rectangle(frame,(x1,y1),(x2,y2),color,2)

            # Display label + speed
            cv2.putText(frame,f"{label} {speed} km/h",
                        (x1,y1-5),
                        cv2.FONT_HERSHEY_SIMPLEX,0.5,color,2)

            # Alert text for stopped vehicles
            if stopped:
                cv2.putText(frame,"STOPPED",(x1,y2+15),
                            cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,255,255),2)

            vehicle_count += 1

    # Update previous centers
    prev_centers = current_centers.copy()

    # ---------------------------------------------------------
    # Congestion estimation based on vehicle count
    if vehicle_count > 10:
        congestion = "HIGH"
    elif vehicle_count > 5:
        congestion = "MEDIUM"
    else:
        congestion = "LOW"

    # ---------------------------------------------------------
    # Display analytics on screen
    cv2.putText(frame,f"Congestion: {congestion}",(10,30),
                cv2.FONT_HERSHEY_SIMPLEX,0.8,(255,255,0),2)

    cv2.putText(frame,f"2-Wheelers: {two_wheeler_count}",(10,65),
                cv2.FONT_HERSHEY_SIMPLEX,0.7,(255,255,0),2)

    cv2.putText(frame,f"4-Wheelers: {four_wheeler_count}",(10,95),
                cv2.FONT_HERSHEY_SIMPLEX,0.7,(255,255,0),2)

    # Reference line
    cv2.line(frame,(0,count_line_y),(640,count_line_y),(0,0,255),2)

    # Show output window
    cv2.imshow("Traffic Monitoring System", frame)

    # Press q to quit
    if cv2.waitKey(30) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
speed

